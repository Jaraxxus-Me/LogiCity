# General simulation settings
simulation:
  map_yaml_file: "config/maps/square_5x5.yaml"       # OpenAI Gym environment name
  agent_yaml_file: "config/agents/easy/test.yaml" # Agents in the simulation
  ontology_yaml_file: "config/rules/ontology.yaml" # Ontology of the simulation
  rule_type: "Z3_RL"               # z3 rl will set the rl_agent with fixed number of other entities, return the groundings as obs, and return the rule reward
  rule_yaml_file: "config/rules/Nav/easy/rl.yaml"                    # Whether to render the environment
  rl: true
  debug: false
  use_multi: false
  agent_region: 140
  rl_agent: 
    max_priority: 7
    use_expert: false
    agent_name: "Car_1"               # ID of the RL agent, this is the agent id in the agent yaml file
    max_horizon: 500                          # Maximum steps in each episode 
    action_space: 4                       # Number of discrete actions, 4 means slow/normal/fast/stop
    action_mapping:                       # Mapping from policy action index to actual action space, see /agent folder
      0: [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
      1: [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0]
      2: [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0]
      3: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
    fov_entities:
      Entity: 5                        # Maximum number of entities in the FOV, include the RL agent

# Stable Baselines specific settings
stable_baselines:
  algorithm: "DQN"
  policy_network: "MlpPolicy"
  policy_kwargs:
    features_extractor_module: "logicity.rl_agent.policy.neural" # Module path
    features_extractor_class: "MLPFeatureExtractor"
    features_extractor_kwargs:
      features_dim: 64
  hyperparameters:
    learning_rate: 0.00003          # Learning rate
    buffer_size: 1000            # Size of the replay buffer
    learning_starts: 1000
    target_update_interval: 500
    train_freq: 4
    gradient_steps: 1
    exploration_fraction: 0.1
    exploration_final_eps: 0.01
    batch_size: 128               # Number of samples in each batch
    verbose: 1                    # Verbosity level
    tensorboard_log: "./tb_logs"  # Tensorboard log directory
  train: false                   # Whether to train the model
  checkpoint_path: "checkpoints/final_models/easy/easy_dqn1.zip"           # Path to a checkpoint to restore the model from
  num_envs: 1                   # Number of environments to run in parallel
  episode_data: "dataset/easy/test_100_episodes.pkl"
