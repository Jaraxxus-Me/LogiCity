# General simulation settings
simulation:
  map_yaml_file: "config/maps/square_5x5.yaml"       # OpenAI Gym environment name
  agent_yaml_file: "config/agents/medium/test.yaml" # Agents in the simulation
  ontology_yaml_file: "config/rules/ontology.yaml" # Ontology of the simulation
  rule_type: "Z3_RL"               # z3 rl will set the rl_agent with fixed number of other entities, return the groundings as obs, and return the rule reward
  rule_yaml_file: "config/rules/Nav/med/test.yaml"                    # Whether to render the environment
  rl: true
  debug: false
  use_multi: false
  agent_region: 140
  rl_agent: 
    max_priority: 22
    use_expert: false
    agent_name: "Car_1"               # ID of the RL agent, this is the agent id in the agent yaml file
    max_horizon: 500                          # Maximum steps in each episode 
    action_space: 4                       # Number of discrete actions, 4 means slow/normal/fast/stop
    action_mapping:                       # Mapping from policy action index to actual action space, see /agent folder
      0: [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
      1: [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0]
      2: [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0]
      3: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
    fov_entities:
      Entity: 5                        # Maximum number of agents in the FOV, include the RL agent
    action_cost:
      0: -2
      1: -1
      2: -2
      3: -3

# Stable Baselines specific settings
stable_baselines:
  algorithm: "HRI"
  policy_network: "HriPolicy"
  policy_kwargs:
    Fast:
      num_background: 21
      num_features: 34
      max_depth: 3
      tgt_arity: 1
      predicates_labels: ['CollidingClose', 'Fast', 'HigherPri', 'IsAmbulance', 'IsAtInter', 'IsBus', 'IsCar', 'IsClose', 'IsInInter', 'IsOld', 'IsPedestrian', 'IsPolice', 'IsReckless', 'IsTiro', 'IsYoung', 'LeftOf', 'NextTo', 'Normal', 'RightOf', 'Stop', 'ident']
    Slow:
      num_background: 22
      num_features: 34
      max_depth: 3
      tgt_arity: 1
      predicates_labels: ['CollidingClose', 'Fast', 'HigherPri', 'IsAmbulance', 'IsAtInter', 'IsBus', 'IsCar', 'IsClose', 'IsInInter', 'IsOld', 'IsPedestrian', 'IsPolice', 'IsReckless', 'IsTiro', 'IsYoung', 'LeftOf', 'NextTo', 'Normal', 'RightOf', 'Slow', 'Stop', 'ident']
    Stop:
      num_background: 22
      num_features: 34
      max_depth: 6
      tgt_arity: 1
      predicates_labels: ['CollidingClose', 'Fast', 'HigherPri', 'IsAmbulance', 'IsAtInter', 'IsBus', 'IsCar', 'IsClose', 'IsInInter', 'IsOld', 'IsPedestrian', 'IsPolice', 'IsReckless', 'IsTiro', 'IsYoung', 'LeftOf', 'NextTo', 'Normal', 'RightOf', 'Slow', 'Stop', 'ident']
  hyperparameters:
    tgt_action: ['Stop', 'Slow', 'Fast']
    default_action: 'Normal'
    threshold: 0.5
    action2idx: {'Slow': 0, 'Normal': 1, 'Fast': 2, 'Stop': 3}
    pred2ind: 
      Fast: {'CollidingClose': 0, 'Fast': 1, 'HigherPri': 2, 'IsAmbulance': 3, 'IsAtInter': 4, 'IsBus': 5, 'IsCar': 6, 'IsClose': 7, 'IsInInter': 8, 'IsOld': 9, 'IsPedestrian': 10, 'IsPolice': 11, 'IsReckless': 12, 'IsTiro': 13, 'IsYoung': 14, 'LeftOf': 15, 'NextTo': 16, 'Normal': 17, 'RightOf': 18, 'Stop': 19, 'ident': 20}
      Slow: {'CollidingClose': 0, 'Fast': 1, 'HigherPri': 2, 'IsAmbulance': 3, 'IsAtInter': 4, 'IsBus': 5, 'IsCar': 6, 'IsClose': 7, 'IsInInter': 8, 'IsOld': 9, 'IsPedestrian': 10, 'IsPolice': 11, 'IsReckless': 12, 'IsTiro': 13, 'IsYoung': 14, 'LeftOf': 15, 'NextTo': 16, 'Normal': 17, 'RightOf': 18, 'Slow': 19, 'Stop': 20, 'ident': 21}
      Stop: {'CollidingClose': 0, 'Fast': 1, 'HigherPri': 2, 'IsAmbulance': 3, 'IsAtInter': 4, 'IsBus': 5, 'IsCar': 6, 'IsClose': 7, 'IsInInter': 8, 'IsOld': 9, 'IsPedestrian': 10, 'IsPolice': 11, 'IsReckless': 12, 'IsTiro': 13, 'IsYoung': 14, 'LeftOf': 15, 'NextTo': 16, 'Normal': 17, 'RightOf': 18, 'Slow': 19, 'Stop': 20, 'ident': 21}
    if_un_pred: 
      Fast: [False, True, False, True, True, True, True, False, True, True, True, True, True, True, True, False, False, True, False, True, False]
      Slow: [False, True, False, True, True, True, True, False, True, True, True, True, True, True, True, False, False, True, False, True, True, False]
      Stop: [False, True, False, True, True, True, True, False, True, True, True, True, True, True, True, False, False, True, False, True, True, False]
  train: false                   # Whether to train the model
  checkpoint_path: "checkpoints/final_models/medium/hri"           # Path to a checkpoint to restore the model from
  num_envs: 1                   # Number of environments to run in parallel
  episode_data: "dataset/medium/test_100_episodes.pkl"
